{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eb29a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## eoAPI Demo\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "This notebook will review the different [eoAPI](https://github.com/developmentseed/eoAPI) services using the Open data from Maxar.\n",
    "\n",
    "### Objective\n",
    "\n",
    "This notebook aims to demonstrate how [eoAPI](https://github.com/developmentseed/eoAPI) can be used to analyze Maxar's high-resolution satellite data to assess the Kahramanmaras earthquakes' impact.\n",
    "\n",
    "### Maxar Open Data\n",
    "\n",
    "Pre and post-event high-resolution satellite imagery in support of emergency planning, risk assessment, monitoring of staging areas and emergency response, damage assessment, and recovery. These images are generated using the Maxar ARD pipeline, tiled on an organized grid in analysis-ready cloud-optimized formats.\n",
    "\n",
    "### STAC and COGs\n",
    "\n",
    "Maxar releases open data for select sudden-onset major crisis events. In addition to making the data (as nice COGs) freely available on AWS, they also add STAC (static) metadata alongside the images. Having the STAC items already created makes ingestion into the PgSTAC database easy (we don't have to produce the items ourselves and thus have to read the images).\n",
    "\n",
    "To learn more about ingesting the Maxar OpenData STAC catalog into PgSTAC see https://github.com/vincentsarago/MAXAR_opendata_to_pgstac.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc106d",
   "metadata": {},
   "source": [
    "# Start the services\n",
    "\n",
    "- Clone the repository: `git clone https://github.com/developmentseed/eoAPI.git`\n",
    "- Navigate to the project: `cd eoAPI`\n",
    "- Run services with `docker compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83178d04",
   "metadata": {},
   "source": [
    "# Ingest STAC Metadata\n",
    "\n",
    "Link: https://stacspec.org/en\n",
    "\n",
    "Once the services are launched, the first step is to ingest STAC **Collections** and **Items** in the **PgSTAC** Database.\n",
    "\n",
    "**Collections**: https://raw.githubusercontent.com/vincentsarago/MAXAR_opendata_to_pgstac/main/collections_assets.json\n",
    "\n",
    "\n",
    "**Items**: https://raw.githubusercontent.com/vincentsarago/MAXAR_opendata_to_pgstac/main/items_s3.json\n",
    "\n",
    "\n",
    "**Requirements**: `pypgstac==0.8.1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0decc1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypgstac==0.9.2 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac[psycopg]==0.9.2) (0.9.2)\n",
      "Requirement already satisfied: cachetools==5.3.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (5.3.3)\n",
      "Requirement already satisfied: fire==0.4.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (0.4.0)\n",
      "Requirement already satisfied: hydraters==0.1.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (0.1.2)\n",
      "Requirement already satisfied: orjson>=3.6.2 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (3.10.15)\n",
      "Requirement already satisfied: plpygis==0.2.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (0.2.2)\n",
      "Requirement already satisfied: pydantic>=1.7 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (2.9.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (2.8.2)\n",
      "Requirement already satisfied: smart-open>=4.2 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (6.3.0)\n",
      "Requirement already satisfied: tenacity==8.1.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (8.1.0)\n",
      "Requirement already satisfied: version-parser>=1.0.1 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (1.0.1)\n",
      "Requirement already satisfied: psycopg-pool==3.1.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pypgstac[psycopg]==0.9.2) (3.1.9)\n",
      "Requirement already satisfied: psycopg==3.1.* in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from psycopg[binary]==3.1.*; extra == \"psycopg\"->pypgstac[psycopg]==0.9.2) (3.1.20)\n",
      "Requirement already satisfied: six in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from fire==0.4.*->pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from fire==0.4.*->pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from psycopg==3.1.*->psycopg[binary]==3.1.*; extra == \"psycopg\"->pypgstac[psycopg]==0.9.2) (4.12.2)\n",
      "Requirement already satisfied: psycopg-binary==3.1.20 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from psycopg[binary]==3.1.*; extra == \"psycopg\"->pypgstac[psycopg]==0.9.2) (3.1.20)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pydantic>=1.7->pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages (from pydantic>=1.7->pypgstac==0.9.2->pypgstac[psycopg]==0.9.2) (2.23.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install \"pypgstac[psycopg]==0.9.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c69ff0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the collections file\n",
    "# !wget https://github.com/vincentsarago/MAXAR_opendata_to_pgstac/raw/main/Maxar/collections.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "673bc641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the items file\n",
    "# ! wget https://github.com/vincentsarago/MAXAR_opendata_to_pgstac/raw/main/Maxar/items.json.zip && unzip items.json.zip && rm -rf items.json.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff01101",
   "metadata": {},
   "source": [
    "#### Use pypgstac to ingest the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af16cb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 128, in read_json\n",
      "    yield orjson.loads(lineout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "orjson.JSONDecodeError: unexpected end of data: line 1 column 2 (char 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/bin/pypgstac\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/pypgstac.py\", line 125, in cli\n",
      "    fire.Fire(PgstacCLI)\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/fire/core.py\", line 466, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/pypgstac.py\", line 74, in load\n",
      "    loader.load_collections(file, method)\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 219, in load_collections\n",
      "    for collection in read_json(file):\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 134, in read_json\n",
      "    json = orjson.loads(f.read())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "orjson.JSONDecodeError: unexpected content after document: line 107 column 1 (char 2850)\n"
     ]
    }
   ],
   "source": [
    "# Ingest the collections\n",
    "!pypgstac load collections collections.json --dsn postgresql://username:password@0.0.0.0:5439/postgis --method insert_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7ded3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/bin/pypgstac\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/pypgstac.py\", line 125, in cli\n",
      "    fire.Fire(PgstacCLI)\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/fire/core.py\", line 466, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/pypgstac.py\", line 76, in load\n",
      "    loader.load_items(file, method, dehydrated, chunksize)\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 614, in load_items\n",
      "    for chunkin in chunked_iterable(items, chunksize):\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 62, in chunked_iterable\n",
      "    chunk = tuple(itertools.islice(it, size))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 590, in read_hydrated\n",
      "    item = self.format_item(line)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 634, in format_item\n",
      "    base_item, key, partition_trunc = self.collection_json(item[\"collection\"])\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/cachetools/__init__.py\", line 702, in wrapper\n",
      "    v = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/eschwartz/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/pypgstac/load.py\", line 190, in collection_json\n",
      "    raise Exception(f\"Error getting info for {collection_id}.\")\n",
      "Exception: Error getting info for MAXAR_BayofBengal_Cyclone_Mocha_May_23.\n"
     ]
    }
   ],
   "source": [
    "# Ingest the items\n",
    "!pypgstac load items items.json --dsn postgresql://username:password@0.0.0.0:5439/postgis --method insert_ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4348e",
   "metadata": {},
   "source": [
    "#### Enable `Context` in pgstac (Optional)\n",
    "\n",
    "See https://github.com/stac-utils/pgstac/blob/main/docs/src/pgstac.md#pgstac-settings-variables\n",
    "\n",
    "The PgSTAC Context extension is not enabled by default because it's \"slows\" down the `/search` request but for this Demo we want it enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc3fa136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from psycopg import sql\n",
    "\n",
    "with psycopg.connect(\n",
    "    \"postgresql://username:password@0.0.0.0:5439/postgis\", \n",
    "    autocommit=True,\n",
    "    options=\"-c search_path=pgstac,public -c application_name=pgstac\",\n",
    ") as conn:            \n",
    "    with conn.cursor() as cursor:        \n",
    "        # Add CONTEXT=ON\n",
    "        pgstac_settings = \"\"\"\n",
    "        INSERT INTO pgstac_settings (name, value)\n",
    "        VALUES ('context', 'on')\n",
    "        ON CONFLICT ON CONSTRAINT pgstac_settings_pkey DO UPDATE SET value = excluded.value;\"\"\"\n",
    "        cursor.execute(sql.SQL(pgstac_settings))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cc240",
   "metadata": {},
   "source": [
    "# STAC Metadata\n",
    "\n",
    "Endpoint: http://127.0.0.1:8081\n",
    "\n",
    "\n",
    "**Requirements**: `httpx ipyleaflet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a912d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python -m pip install httpx ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ed3efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import httpx\n",
    "\n",
    "import ipyleaflet\n",
    "\n",
    "stac_endpoint = \"http://127.0.0.1:8081\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cfd71",
   "metadata": {},
   "source": [
    "### Collection\n",
    "\n",
    "If you look in `https://stac.eoapi.dev/collections` response, you'll find one collection for the Kahramanmaras earthquake named `MAXAR_Kahramanmaras_turkey_earthquake_23`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44105f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of collections: 1\n",
      "Collection names: [\n",
      "  \"atlas-soc\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# list the collections and find the collection_id associated to the `kahramanmaras` event\n",
    "collections = httpx.get(f\"{stac_endpoint}/collections\").json()\n",
    "collection_names = ([c[\"id\"] for c in collections[\"collections\"]])\n",
    "\n",
    "print(f\"Number of collections: {len(collection_names)}\")\n",
    "print(f\"Collection names: {json.dumps(collection_names, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7176b3",
   "metadata": {},
   "source": [
    "Lest focus on the data acquired for the M7.8 and M7.5 Kahramanmaras earthquakes in Turkey on February 6, 2023.\n",
    "\n",
    "More on the event: https://www.usgs.gov/news/featured-story/m78-and-m75-kahramanmaras-earthquake-sequence-near-nurdagi-turkey-turkiye\n",
    "\n",
    "\n",
    "Collection's Name: **MAXAR_Kahramanmaras_turkey_earthquake_23**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f0afd",
   "metadata": {},
   "source": [
    "Let's check the collection's metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02f9b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8081/collections/MAXAR_Kahramanmaras_turkey_earthquake_23\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "code": "NotFoundError",
       "description": "Collection MAXAR_Kahramanmaras_turkey_earthquake_23 does not exist."
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'extent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 29\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(collection_info)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m display(JSON(collection_info))\n\u001b[1;32m     12\u001b[0m geojson \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatureCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     15\u001b[0m         {\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     18\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolygon\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m: [[\n\u001b[1;32m     20\u001b[0m                     [bbox[\u001b[38;5;241m0\u001b[39m], bbox[\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m     21\u001b[0m                     [bbox[\u001b[38;5;241m2\u001b[39m], bbox[\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m     22\u001b[0m                     [bbox[\u001b[38;5;241m2\u001b[39m], bbox[\u001b[38;5;241m3\u001b[39m]],\n\u001b[1;32m     23\u001b[0m                     [bbox[\u001b[38;5;241m0\u001b[39m], bbox[\u001b[38;5;241m3\u001b[39m]],\n\u001b[1;32m     24\u001b[0m                     [bbox[\u001b[38;5;241m0\u001b[39m], bbox[\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m     25\u001b[0m                 ]]\n\u001b[1;32m     26\u001b[0m             },\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m: {}\n\u001b[1;32m     28\u001b[0m         }\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcollection_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mextent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m     ]\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     33\u001b[0m mainbbox \u001b[38;5;241m=\u001b[39m collection_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     35\u001b[0m m \u001b[38;5;241m=\u001b[39m ipyleaflet\u001b[38;5;241m.\u001b[39mleaflet\u001b[38;5;241m.\u001b[39mMap(\n\u001b[1;32m     36\u001b[0m     center\u001b[38;5;241m=\u001b[39m((mainbbox[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m mainbbox[\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m,(mainbbox[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m mainbbox[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     37\u001b[0m     zoom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m\n\u001b[1;32m     38\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'extent'"
     ]
    }
   ],
   "source": [
    "## NOTE had to reload jupyter notebook, see https://stackoverflow.com/questions/74287757/ipyleaflet-map-not-rendering-in-jupyter-notebook-on-install\n",
    "from IPython.display import display, JSON\n",
    "collection_id = \"MAXAR_Kahramanmaras_turkey_earthquake_23\"\n",
    "\n",
    "collection_info = httpx.get(f\"{stac_endpoint}/collections/{collection_id}\").json()\n",
    "\n",
    "print(f\"{stac_endpoint}/collections/{collection_id}\")\n",
    "\n",
    "# print(collection_info)\n",
    "display(JSON(collection_info))\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [[\n",
    "                    [bbox[0], bbox[1]],\n",
    "                    [bbox[2], bbox[1]],\n",
    "                    [bbox[2], bbox[3]],\n",
    "                    [bbox[0], bbox[3]],\n",
    "                    [bbox[0], bbox[1]],\n",
    "                ]]\n",
    "            },\n",
    "            'properties': {}\n",
    "        }\n",
    "        for bbox in collection_info[\"extent\"][\"spatial\"][\"bbox\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "mainbbox = collection_info[\"extent\"][\"spatial\"][\"bbox\"][0]\n",
    "\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((mainbbox[1] + mainbbox[3]) / 2,(mainbbox[0] + mainbbox[2]) / 2),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(data=geojson)\n",
    "m.add_layer(geo_json)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7a387",
   "metadata": {},
   "source": [
    "Each collection can have spatial and temporal extents. As for the spatial extent, a collection can have multiple temporal extents, but its first one represents the combined min/max of all the intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection_info[\"extent\"][\"temporal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ae5e3-84a6-46bd-a792-215c108e0b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/78299658/display-json-data-or-a-dictionary-so-thats-its-collapsable-in-a-python-jupyter\n",
    "import json\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "display(JSON(geojson, expanded=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1db99",
   "metadata": {},
   "source": [
    "## Items\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "- List all items for a specific collection using the `/collections/{collection_id}/items` endpoint\n",
    "- Talk about the `limit` parameter\n",
    "- Visualize all items on a map\n",
    "- Talk about the item metadata\n",
    "\n",
    "- List the Assets available for one Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT WORKING, no context\n",
    "\n",
    "items = httpx.get(f\"{stac_endpoint}/collections/{collection_id}/items\").json()\n",
    "\n",
    "\n",
    "# print(f\"Nb Items in Db: {items['context']['matched']}\")  # This is only available if CONTEXT=ON\n",
    "print(f\"Returned {len(items['features'])} Items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0efb74",
   "metadata": {},
   "source": [
    "As you can see below, the `/items` endpoints returned only 10 items. To return more data, we need to either use the `paging` mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992501d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kahramanmaras_items = []\n",
    "\n",
    "url = f\"{stac_endpoint}/collections/{collection_id}/items\"\n",
    "# while True:\n",
    "for _ in range(5):\n",
    "    items = httpx.get(url, params={\"limit\": 100}).json()\n",
    "    \n",
    "    kahramanmaras_items.extend(items[\"features\"])\n",
    "    next_link = list(filter(lambda link: link[\"rel\"] == \"next\", items[\"links\"]))\n",
    "    if next_link:\n",
    "        url = next_link[0][\"href\"]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Nb Items: {len(kahramanmaras_items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cc982-2dff-49be-84ff-7b6f9ce2ed91",
   "metadata": {},
   "source": [
    "## LEFT OFF HERE 2/20\n",
    "slow to load all the item...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((mainbbox[1] + mainbbox[3]) / 2,(mainbbox[0] + mainbbox[2]) / 2),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "event_date = datetime(2023, 2, 6, hour=0, minute=0)\n",
    "\n",
    "# Use a styling function to show where we have before/after items\n",
    "def style_function(feature):\n",
    "    d = datetime.strptime(feature[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return {\n",
    "        \"fillOpacity\": 0.1,\n",
    "        \"weight\": 0.1,\n",
    "        # Blue for pre-event / red for post-event\n",
    "        \"fillColor\": \"#0000ff\" if d < event_date else \"#ff0000\"\n",
    "    }\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(data={\"type\": \"FeatureCollection\", \"features\": kahramanmaras_items}, style_callback=style_function)\n",
    "m.add_layer(geo_json)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55f253",
   "metadata": {},
   "source": [
    "#####  Item metadata \n",
    "\n",
    "Each item should have an `id`, a `geometry`, some links to `Assets`, and a set of properties.\n",
    "\n",
    "Item specification: https://github.com/radiantearth/stac-spec/blob/master/item-spec/item-spec.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = kahramanmaras_items[0]\n",
    "print(\"Item example:\")\n",
    "# print(json.dumps(item, indent=4))\n",
    "JSON(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f632955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Item Id\", item[\"id\"])\n",
    "print(\"Item Assets:\", list(item[\"assets\"].keys()))\n",
    "print(\"Item Properties:\")\n",
    "# print(json.dumps(item[\"properties\"], indent=4))\n",
    "JSON(item[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f4575",
   "metadata": {},
   "source": [
    "#### Find acquisition times\n",
    "\n",
    "Every item should have either a `datetime` or a `start/end_datetime` property. For the Maxar dataset, we are assuming that `datetime` is acquisition times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9013bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = {item[\"properties\"][\"datetime\"] for item in kahramanmaras_items}\n",
    "print(\"Dates:\", sorted(list(datetimes))[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e73ff",
   "metadata": {},
   "source": [
    "Let's sort the items in two categories: `before` and `after` the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021248b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_date = datetime(2023, 3, 6, hour=0, minute=0)\n",
    "\n",
    "pre_items = list(\n",
    "    filter(\n",
    "        lambda item: datetime.strptime(item[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\") < event_date, \n",
    "        kahramanmaras_items\n",
    "    )\n",
    ")\n",
    "\n",
    "post_items = list(\n",
    "    filter(\n",
    "        lambda item: datetime.strptime(item[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\") >= event_date, \n",
    "        kahramanmaras_items\n",
    "    )\n",
    ")\n",
    "print(\"PRE event items:\", len(pre_items))\n",
    "print(\"POST event items:\", len(post_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but using the STAC API\n",
    "pre_items_api = httpx.post(\n",
    "    f\"{stac_endpoint}/search\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"lt\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, \"2023-02-06T00:00:00Z\"\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "post_items_api = httpx.post(\n",
    "    f\"{stac_endpoint}/search\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"gte\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, \"2023-02-06T00:00:00Z\"\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "# print(f\"Nb Items in Db: {pre_items_api['context']['matched']}\")  # This is only available if CONTEXT=ON\n",
    "print(f\"Nb Items in Db: {pre_items_api['numberMatched']}\")  # This is only available if CONTEXT=ON\n",
    "print(\"pre\")\n",
    "display(JSON(pre_items_api))\n",
    "print(\"post\")\n",
    "display(JSON(post_items_api))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2e374",
   "metadata": {},
   "source": [
    "## Asset visualization\n",
    "\n",
    "So we have **2115** items for the `MAXAR_Kahramanmaras_turkey_earthquake_23` collection, and each item has **4** assets (this is also found at the collection level in the `item_assets extension`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca07238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(item[\"assets\"].keys()))\n",
    "print()\n",
    "for name, asset in item[\"assets\"].items():\n",
    "    print(name, \": \", asset[\"title\"], \": \", asset[\"type\"])\n",
    "    print(\"\\t\", asset[\"href\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1a304",
   "metadata": {},
   "source": [
    "In eoAPI, we have a raster API connected to the PgSTAC database. The service is built using [titiler-pgstac](http://github.com/stac-utils/titiler-pgstac) and can be used to visualize `Item` or `Mosaics` (multiple items).\n",
    "\n",
    "Endpoint: [http://127.0.0.1:8082](http://127.0.0.1:8082)\n",
    "\n",
    "We know we have 4 assets for each item, and 3 are of `Cloud-Optimized` type. Let's use the raster API to visualize them.\n",
    "\n",
    "First, let's get the Raster metadata for each `raster` asset. The raster API will use the asset's `type` metadata to filter non-raster dataset (e.g.  `application/geopackage+sqlite3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dceef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_endpoint = \"http://127.0.0.1:8082\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a45bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching Raster information for all the `raster` assets\n",
    "item_id = item[\"id\"]\n",
    "\n",
    "url = f\"{raster_endpoint}/collections/{collection_id}/items/{item_id}/info\"\n",
    "print(f\"Fetching Raster info for Item {item_id} from {url}\")\n",
    "info = httpx.get(url).json()\n",
    "\n",
    "print(\"Returned metadata for Assets:\", list(info.keys()))\n",
    "print()\n",
    "display(JSON(info))\n",
    "print()\n",
    "# for name, asset in info.items():\n",
    "    # print(name, asset[\"minzoom\"], asset[\"maxzoom\"])\n",
    "    # FAILS missing minzoom/maxzoom (nowhere in that json)\n",
    "    # also, needed to mount aws creds, should note that here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87b045",
   "metadata": {},
   "source": [
    "The `/collections/{collectionId}/items/{itemId}/info` endpoint returned metadata for 3 assets (the raster ones). We now know more about each asset (datatype, zoom levels, number of bands), which can help us create tiles urls.\n",
    "\n",
    "### Asset on Map\n",
    "\n",
    "To visualize an asset on a Map, we need to construct a `Tile URL`. To ease the task we can use the raster's service `/collections/{collection_id}/items/{item_id}/tilejson.json` endpoint, but here are the requirements:\n",
    "\n",
    "- HAVE TO pass `assets` or `expression` parameter\n",
    "- CAN pass `min/max zooms` (which will avoid under/over-zooming)\n",
    "- CAN pass `rescale` parameter if datatype is not compatible with PNG/JPEG output format\n",
    "- CAN pass `asset_bidx` parameter to select band combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d6e50-aa9f-48fa-9ecd-2dcedeede8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{raster_endpoint}/collections/{collection_id}/items/{item_id}/WebMercatorQuad/tilejson.json\"\n",
    "print(f\"Fetching Raster info for Item {item_id} from {url}\")\n",
    "info = httpx.get(url, \n",
    "                 params = (\n",
    "        (\"assets\", \"visual\"),  # THIS PARAMETER IS MANDATORY\n",
    "        (\"minzoom\", 12),  # By default the tiler will use 0\n",
    "        (\"maxzoom\", 19), # By default the tiler will use 24\n",
    "    )\n",
    ").json()\n",
    "JSON(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `visual` Asset\n",
    "\n",
    "# FIX URL\n",
    "url = f\"{raster_endpoint}/collections/{collection_id}/items/{item_id}/WebMercatorQuad/tilejson.json\"\n",
    "print(\"url\", url)\n",
    "\n",
    "tilejson = httpx.get(\n",
    "    url,\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS PARAMETER IS MANDATORY\n",
    "        (\"minzoom\", 12),  # By default the tiler will use 0\n",
    "        (\"maxzoom\", 19), # By default the tiler will use 24\n",
    "    )\n",
    ").json()\n",
    "print(\"tilejson\")\n",
    "display(JSON(tilejson))\n",
    "\n",
    "bounds = tilejson[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=12\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data=item,\n",
    "    style={\n",
    "        'opacity': 1, 'dashArray': '9', 'fillOpacity': 0., 'weight': 4\n",
    "    }\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson[\"tiles\"][0],\n",
    "    min_zoom=tilejson[\"minzoom\"],\n",
    "    max_zoom=tilejson[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0b189-caec-419d-bdea-3c30fff50b5b",
   "metadata": {},
   "source": [
    "# LEFT OFF HERE 2/21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02b6ae",
   "metadata": {},
   "source": [
    "## Mosaics\n",
    "\n",
    "As mentioned and shown with `titiler-pgstac`, we can visualize an item's asset. Still, the raster API's real power is to create a virtual mosaic dynamically and merge multiple items on the fly.\n",
    "\n",
    "Learn more: http://github.com/stac-utils/titiler-pgstac.\n",
    "\n",
    "Let's create `mosaics` for `pre` and `post` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331929fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_date = \"2023-02-06T00:00:00Z\"\n",
    "\n",
    "\n",
    "# Let's focus on Kahramanmara≈ü city \n",
    "bounds = [36.83064386785452, 37.53123515817725, 37.03859654890988, 37.63167525356958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c276ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_mosaic = httpx.post(\n",
    "    f\"{raster_endpoint}/searches/register\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"lt\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, event_date\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            \"sortby\": [\n",
    "                {\n",
    "                    \"field\": \"tile:clouds_percent\",\n",
    "                    \"direction\": \"asc\"\n",
    "                },\n",
    "            ],\n",
    "            \"metadata\":{\n",
    "                \"name\": \"Maxar Kahramanmaras - Pre event\",\n",
    "                \"bounds\": bounds,\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "post_mosaic = httpx.post(\n",
    "    f\"{raster_endpoint}/searches/register\",\n",
    "    data=json.dumps(\n",
    "        {\n",
    "            \"filter-lang\": 'cql2-json',\n",
    "            \"filter\": {\n",
    "                \"op\": 'and', \n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"op\": \"in\", \n",
    "                        \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "                    },\n",
    "                    {\n",
    "                        \"op\": \"ge\", \n",
    "                        \"args\": [\n",
    "                            {\"property\": \"datetime\"}, event_date\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            \"sortby\": [\n",
    "                {\n",
    "                    \"field\": \"tile:clouds_percent\",\n",
    "                    \"direction\": \"asc\"\n",
    "                },\n",
    "            ],\n",
    "            \"metadata\":{\n",
    "                \"name\": \"Maxar Kahramanmaras - Port event\",\n",
    "                \"bounds\": bounds,\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    )\n",
    ").json()\n",
    "\n",
    "print(\"Pre event Mosaic\")\n",
    "print(json.dumps(pre_mosaic, indent=4))\n",
    "print()\n",
    "print(\"Post event Mosaic\")\n",
    "print(json.dumps(post_mosaic, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5f539",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "The `mosaic` corresponds to an STAC Search query. Because we use `PgSTAC` backend, we can make use of the `filter` extension to construct complex queries: https://github.com/stac-api-extensions/filter\n",
    "\n",
    "```json\n",
    "{\n",
    "    // PgSTAC accepts multiple languages for filtering; here we will use cql2-json\n",
    "    \"filter-lang\": 'cql2-json',\n",
    "    // We tell PgSTAC to `register` a `search` request with the following filter:\n",
    "    \"filter\": {\n",
    "        \"op\": 'and',\n",
    "        \"args\": [\n",
    "            // Item's collection HAS TO be in `[collection_id]`\n",
    "            {\n",
    "                \"op\": \"in\",\n",
    "                \"args\": [{\"property\": \"collection\"}, [collection_id]]\n",
    "            },\n",
    "            // Filter Items that have datetime `lt` than the event date\n",
    "            {\n",
    "                \"op\": \"lt\",\n",
    "                \"args\": [\n",
    "                    {\"property\": \"datetime\"}, event_date\n",
    "                ]\n",
    "            },\n",
    "            // Sort the items using clouds_percent property to make sure cloudless images are on the top\n",
    "            \"sortby\": [\n",
    "                {\n",
    "                    \"field\": \"tile:clouds_percent\",\n",
    "                    \"direction\": \"asc\"\n",
    "                },\n",
    "            ],\n",
    "            // titiler-pgstac accept some additional metadata\n",
    "            // <https://stac-utils.github.io/titiler-pgstac/advanced/metadata/>\n",
    "            // One is useful: `bounds`. When creating a mosaic, the tiler will have no idea\n",
    "            // where the items will be before trying to create each tile. To avoid trying to request\n",
    "            // tiles where we know we don't have any items, we can add the collection's extent to the\n",
    "            // mosaic metadata.\n",
    "            // The tiler service will then return the bounds in the tilejson document for the\n",
    "            // client application.\n",
    "            \"metadata\":{\n",
    "                \"name\": \"Maxar Kahramanmaras - Pre event\",\n",
    "                \"bounds\": bounds,\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "API Response:\n",
    "\n",
    "The raster service will return a `searchid` hash (`mosaic id`), which we can use to construct a tile URL.\n",
    "\n",
    "To create a valid tile URL, we will again need to pass an `assets` parameter to tell the tiler which assets we want to visualize. We can also set the min/max zoom limits to avoid underzooming (opening too many files) and overzooming.\n",
    "\n",
    "See the complete list of options: https://stac-utils.github.io/titiler-pgstac/mosaic_endpoints/#tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = pre_mosaic[\"id\"]\n",
    "\n",
    "tilejson_pre = httpx.get(\n",
    "    f\"{raster_endpoint}/searches/{search_id}/WebMercatorQuad/tilejson.json\",\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS IS MANDATORY\n",
    "        (\"minzoom\", 12),\n",
    "        (\"maxzoom\", 19), \n",
    "    )\n",
    ").json()\n",
    "display(JSON(tilejson_pre))\n",
    "\n",
    "bounds = tilejson_pre[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=12\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data={\"type\": \"FeatureCollection\", \"features\": pre_items}, \n",
    "    style={\n",
    "        \"fillOpacity\": 0,\n",
    "        \"weight\": 1,\n",
    "    },\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_pre[\"tiles\"][0],\n",
    "    min_zoom=tilejson_pre[\"minzoom\"],\n",
    "    max_zoom=tilejson_pre[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74df2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = post_mosaic[\"id\"]\n",
    "\n",
    "tilejson_post = httpx.get(\n",
    "    f\"{raster_endpoint}/searches/{search_id}/WebMercatorQuad/tilejson.json\",\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS IS MANDATORY\n",
    "        (\"minzoom\", 12),\n",
    "        (\"maxzoom\", 19), \n",
    "    )\n",
    ").json()\n",
    "display(JSON(tilejson_post))\n",
    "\n",
    "bounds = tilejson_post[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=10\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data={\"type\": \"FeatureCollection\", \"features\": post_items}, \n",
    "    style={\n",
    "        \"fillOpacity\": 0,\n",
    "        \"weight\": 0.5,\n",
    "    },\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_post[\"tiles\"][0],\n",
    "    min_zoom=tilejson_post[\"minzoom\"],\n",
    "    max_zoom=tilejson_post[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d900b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=(37.571788, 36.919100),\n",
    "    zoom=12,\n",
    ")\n",
    "\n",
    "bounds = tilejson_pre[\"bounds\"]\n",
    "before_layer = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_pre[\"tiles\"][0],\n",
    "    min_zoom=tilejson_pre[\"minzoom\"],\n",
    "    max_zoom=tilejson_pre[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "    ],\n",
    ")\n",
    "\n",
    "bounds = tilejson_post[\"bounds\"]\n",
    "after_layer = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson_post[\"tiles\"][0],\n",
    "    min_zoom=tilejson_post[\"minzoom\"],\n",
    "    max_zoom=tilejson_post[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "    ],\n",
    ")\n",
    "\n",
    "control = ipyleaflet.leaflet.SplitMapControl(left_layer=before_layer, right_layer=after_layer)\n",
    "m.add_control(control)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bc02d",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "### Spin Up Your Own eoAPI Instance\n",
    "\n",
    "You've seen what eoAPI can do with Maxar data in the context of the Turkey Earthquakes. Interested in setting up your own eoAPI service? It's straightforward! Follow the 'Getting Started' section of the [eoAPI GitHub repository](https://github.com/developmentseed/eoAPI) to get your instance up and running. This will give you greater control and customization options.\n",
    "\n",
    "### Contribute Your Data\n",
    "\n",
    "Consider contributing if you've used Maxar data for similar analyses or have other datasets that could benefit the community. Uploading your data to your eoAPI instance can provide more diverse examples and help in various applications.\n",
    "\n",
    "### Community-Driven Examples\n",
    "\n",
    "The examples you see here, including this notebook, are often community-driven. We encourage you to contribute your analyses, workflows, or visualizations. Your insights could be invaluable for helping others.\n",
    "\n",
    "### Have Questions? Join the Discussion!\n",
    "\n",
    "If you have questions, feedback, or want to engage with the eoAPI community, please join the [GitHub discussions](https://github.com/developmentseed/eoAPI/discussions). It's a great place to ask questions, share your experiences, and connect with others interested in eoAPI and its components. \n",
    "\n",
    "---\n",
    "\n",
    "Thank you for taking the time to go through this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
